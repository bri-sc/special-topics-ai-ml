{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives\n",
    "\n",
    "The derivative describes the rate of change of a curve and, at a given point on the curve, tells the gradient of the tangent line (see {numref}`calculus-intro`). \n",
    "Mathematically, where a one-dimensional curve is $f(x)$, the derivative is defined as:\n",
    "\n",
    "$$\n",
    "f'(x) = \\lim_{\\Delta x \\to 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}.\n",
    "$$ (derivative-definition)\n",
    "\n",
    "That is to say that the derivative describes how $f(x)$ changes at an infinitesimally small change in $x$, $\\Delta x \\to 0$.\n",
    "\n",
    "## How To Find a Derivative\n",
    "\n",
    "To investigate how to find a gradient, let's consider a plot of $f(x) = y = x^2$. \n",
    "We can plot this with Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = x ** 2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this system, the gradient at any point on the plot, $m$, can be calculated as the change in $\\Delta y / \\Delta x$. \n",
    "We can describe the numerator of that function in terms of $x$ alone, \n",
    "\n",
    "$$\n",
    "\\Delta y = (x + \\Delta x) ^ 2) - x^2.\n",
    "$$\n",
    "\n",
    "Therefore, we can rewrite the gradient as, \n",
    "\n",
    "$$\n",
    "m = \\frac{x^2 + 2x \\Delta x + \\Delta x^2 - x}{\\Delta x},\n",
    "$$\n",
    "\n",
    "and then simply to get, \n",
    "\n",
    "$$\n",
    "m = 2x + \\Delta x. \n",
    "$$(diff-result)\n",
    "\n",
    "This means that as $\\Delta x \\to 0$, the gradient tends to $2x$. \n",
    "For example, for the plot above, at $x = 0.5$, we can find the gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = 2 * 0.5\n",
    "offset = 0.5 ** 2 - gradient * 0.5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.plot(x, gradient * x + offset, '--', \n",
    "        label='First Derivative at 0.5')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see the dashed line is at a tangent to the $x^2$ line at $x=0.5$. \n",
    "\n",
    "### Generalisation\n",
    "\n",
    "This result can be generalised with the following formula, \n",
    "\n",
    "$$\n",
    "\\frac{\\text{d}(x^n)}{\\text{d}x} = nx^{n-1}, \n",
    "$$ (diff-general)\n",
    "\n",
    "which will give the gradient at any point along the curve. \n",
    "\n",
    "## Finding Derivatives in Python\n",
    "\n",
    "An interesting Python library that can be used for *symbolic mathematics*, which means maths with symbols, i.e., $x$, $y$, and $z$ instead of specific numerical values, known as `sympy`. \n",
    "This library is designed explicitly for symbolic mathematics, which means that performing numerical calculations is *generally speaking* a bad idea. \n",
    "We present it here as a tool to aid understanding. \n",
    "\n",
    "`sympy` can be used to find the derivative of a given function. \n",
    "For example, this can be used to compute the same derivative as computed above manually. \n",
    "\n",
    "````{margin}\n",
    "```{warning}\n",
    "The `diff` function takes to arguments, the function to differentiate and the symbol to perform the derivative with respect to.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, diff\n",
    "\n",
    "x = symbols('x')\n",
    "diff(x ** 2, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library is a powerful tool that we will return to in this section. \n",
    "\n",
    "### Numerical Derivative Estimation\n",
    "\n",
    "We can also use Python to estimate the derivative explictly. \n",
    "For this, we compute the values of a function at $x\\pm \\text{d}x$ and calculate the slope around $x$, where $\\text{d}x$ is a very small value. \n",
    "For example, if we want to estimate the derivative of $x^2$ at $x=0.4$, we know from Eqn. {eq}`diff-result` that the gradient will be $0.8$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 1e-7\n",
    "x = np.array([0.4 - dx, 0.4 + dx])\n",
    "y = x ** 2\n",
    "gradient = np.diff(y) / np.diff(x)\n",
    "gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this approach increases with decreasing values of `dx`. \n",
    "Let us see how differentiation can be used practically in our data science applications. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "special-topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
