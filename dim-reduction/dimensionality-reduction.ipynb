{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Dimensionality Reduction?\n",
    "\n",
    "Dimensionality reduction algorithms are a class of unsupervised machine learning algorithms. \n",
    "The aim of a dimensionality reduction algorithm is to reduce the number of features in a dataset, without losing too much important information. \n",
    "\n",
    "Humans are bad at visualisation of data in more than two dimensions. \n",
    "However, humans are very good at identification of trends in data. \n",
    "Therefore, it can be desirable to reduce the number of features in a given dataset to facilitate visualisation. \n",
    "Often this practice is then followed by approaches such as trend identification (i.e., linear regression) or clustering. \n",
    "\n",
    "```{figure} ../images/dimensionality-reduction.png\n",
    "---\n",
    "name: dr\n",
    "width: 100%\n",
    "---\n",
    "A visual representation of dimensionality reduction, from three to one dimensions.\n",
    "```\n",
    "\n",
    "There are many dimensionality reduction algorithms, but we will look in detail at just a couple; namely; principal components analysis (PCA) and t-distributed stochastic neighbour embedding (*t*-SNE). \n",
    "\n",
    "````{margin}\n",
    "```{note}\n",
    "An [abalone](https://en.wikipedia.org/wiki/Abalone) is a marine mollusc that are commonly eaten by humans. \n",
    "```\n",
    "````\n",
    "To show the different dimensionality reduction algorithms, we will use some openly available datasets. \n",
    "Let's look at these datasets in detail before we get started. \n",
    "\n",
    "## Abalone Dataset\n",
    "This data was sourced from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/1/abalone), to demonstrate the different dimensionality reduction algorithms that we will look at. \n",
    "The file has been modified to include the names of the features, and can be downloaded [here](./../data/abalone.csv).\n",
    "\n",
    "Let's have a look at this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./../data/abalone.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data has 4177 entries, each with 9 features.\n",
    "These 9 features describe the size of the abalone samples (length, diameter, weight, etc.) and the number of rings in their shells. \n",
    "This final feature is a descriptor of the age of the abalone.\n",
    "The number of rings are not straight forward to measure, so it is desirable to estimate the age from these other parameters. \n",
    "\n",
    "Before we continue, it is important that we check for any missing data.\n",
    "Missing data, would typically be stored as a null-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no features with missing data (i.e., no null-values). \n",
    "If null-values were present, depending on the algorithm being used, it may be necessary to remove these datapoints. \n",
    "\n",
    "In addition to checking for missing data, we should also consider the nature of some of the data present. \n",
    "For example, the `sex` data is not numerical; either male or female.\n",
    "This data is referred to as **catagorical**, as in it has catagories. \n",
    "Similar to missing data, this may not be compatible with the algorithm we apply. \n",
    "\n",
    "## Breast Cancer\n",
    "\n",
    "Another dataset that we will look it is the Wisconson Breast Cancer dataset, sourced also from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic). \n",
    "This dataset is information about the size, shape and texture of breast cancer tumours, and has been tagged with information about whether the tumour was found to be benign (not harmful in effect) or malignant (infectuous). \n",
    "This dataset has been reduced to makes it suit the pedogogical purposes of this work more, and can be downloaded [here](./../data/breast-cancer.csv). \n",
    "Let's look at the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./../data/breast-cancer.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the abalone dataset, the null-values have been stripped from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten Digits Dataset\n",
    "\n",
    "A popular dataset used for looking at machine learning algorithms is the MNIST handwritten digits dataset. \n",
    "This data contains a series of images of digits that have been handwritten. \n",
    "Let's load the data in and have a look at the structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./../data/mnist.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this dataset has an integer value for each of 784 pixels as well as a label, where the label indicates the true value of the digits that has been written. \n",
    "We can visualise some of the images by reshaping the data appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "ax.imshow(montage(data[[f'pixel{i+1}' for i in range(784)]].loc[:15].values.reshape(16, 28, 28)))\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large dataset, with a lot of features for us to train or algorithms against. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "special-topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
