{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "The matrix implementation of linear regression discussed previously naturally extends to data with more than one feature. \n",
    "For example, let's look at applying to the [student performance](../setup/datasets.html) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/student-performance.csv')  \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the Extracurricular Activities is a discrete variable, either Yes or No. \n",
    "It is necessary that we encode this as an integer to work with linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Encoded EA'] = [1 if x == 'Yes' else 0 for x in data['Extracurricular Activities']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the success of the linear regressor, we will split the data, using a process that will be familiar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training set, we will produce the $\\mathbf{X}$ matrix. \n",
    "We achieve this by adding the column of ones to our independent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.hstack([np.ones((train.shape[0], 1)), \n",
    "               train.drop(['Performance Index', 'Extracurricular Activities'], axis=1).values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are five features in the dataset, and by using multiple linear regression, we can feed these all in the prediction.\n",
    "The outcome that we are assessing against is the Performance Index.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Performance Index'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the normal equations to estimate $\\beta$. \n",
    "````{margin}\n",
    "```{note}\n",
    "This is entirely equivalent to scikit-learn's `LinearRegression` method. \n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have an understanding of the *power* that each feature has on the data. \n",
    "Note, it would be necessary to normalise our data to draw conclusions from these $\\beta$ values. \n",
    "However, here we are interested in the ability for the model to predict new performance based on our features. \n",
    "We can compute the estimated Performance Index, using this multiple linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.hstack([np.ones((test.shape[0], 1)), \n",
    "                    test.drop(['Performance Index', 'Extracurricular Activities'], axis=1).values])\n",
    "\n",
    "y_est = X_test @ beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the accuracy of this approach with a predicted versus actual plot, where the dashed line indicates perfect estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_est, test['Performance Index'], '.')\n",
    "ax.plot([0, 100], [0, 100], 'k--')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides a good visual indication of the accuracy of the linear regression. \n",
    "However, we can also calculate metrics, such as the mean-squared error (MSE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(test['Performance Index'], y_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric is computed as the mean of the square of difference between the estimated and the true value,\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_{\\text{true}} - y_{\\text{est}}) ^ 2.\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "special-topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
