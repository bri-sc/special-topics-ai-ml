{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Linear regression is a fundamental component of data analysis and the backbone of modern machine-learning approaches. \n",
    "Linear regression is the modelling of a linear relationship between two parameters, the dependent and independent variables. \n",
    "For example, consider the following data measuring the heart rate of patients while they are walking/running on an elliptical machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('../data/heart-rate.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "data.plot(x='speed (kph)', y='heart rate (bpm)', kind='scatter', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data appears to be linear, therefore it is a good use of linear regression to describe the trend in the data. \n",
    "The aim of linear regression is find the parameters $\\beta$ that solve the following equation, \n",
    "\n",
    "$$\n",
    "\\mathbf{X}\\beta = \\mathbf{y},\n",
    "$$\n",
    "\n",
    "where, $\\mathbf{y}$ is a column vector containing $n$ independent variables, $\\mathbf{X}$ is a $n\\times p$ matrix, where $p$ is the number of features in the data, and $\\mathbf{\\beta}$ is another column vector of length $p$.\n",
    "$\\beta$ will describe the impact that each feature has on the data. \n",
    "\n",
    "Considering the simple linear regression case, where there are two parameters to be determined, the slope and the intercept. \n",
    "Therefore, $\\mathbf{X}$ will have two columns, the first column will be a column where all the elements have the value 1, and the second column is then the dependent variables. \n",
    "So for the heart rate data previously, the $\\mathbf{X}$ matrix would be\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1.6 \\\\ 1 & 3.1 \\\\ 1 & 4.0 \\\\ 1 & 5.0 \\\\ 1 & 6.0 \\\\ 1 & 6.9 \\\\ 1 & 7.7 \\\\ 1 & 8.7 \\\\ 1 & 12.4 \\\\ 1 & 15.3 \\end{bmatrix}.\n",
    "$$ (X-matrix)\n",
    "\n",
    "This matrix can be generated as a NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = data['speed (kph)']\n",
    "X = np.array([np.ones_like(x), x]).T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\mathbf{y}$ vector will then be the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['heart rate (bpm)'].T\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the estimates of the slope and intercept, $\\hat{\\mathbf{\\beta}}$, are found by minimising the sum of squared differences between $\\mathbf{X}\\mathbf{\\beta}$ and $\\mathbf{y}$, which can be referred to as $S(\\mathbf{\\beta})$. \n",
    "This gives rise to what is known as the normal equations: \n",
    "\n",
    "$$\n",
    "(\\mathbf{X}^\\top\\mathbf{X})\\hat{\\mathbf{\\beta}} =  \\mathbf{X}^\\top\\mathbf{y}.\n",
    "$$ (normal-equations)\n",
    "\n",
    "The normal equations can be rearranged to give $\\hat{\\mathbf{\\beta}}$, \n",
    "\n",
    "````{margin}\n",
    "```{note}\n",
    "This matrix multiplication function may be familiar.\n",
    "```\n",
    "````\n",
    "$$\n",
    "\\hat{\\mathbf{\\beta}} = (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top\\mathbf{y}.\n",
    "$$ (beta-hat)\n",
    "\n",
    "This allows us to write the following NumPy matrix mathematics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the intercept, which is linked to the column of ones, is 63.36 bpm and the gradient is 3.75 bpm/kph.\n",
    "We can use this to plot this linear trend alongside the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "data.plot(x='speed (kph)', y='heart rate (bpm)', kind='scatter', ax=ax)\n",
    "ax.plot(x, X @ beta, 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{margin}\n",
    "```{note} \n",
    "You may notice that to obtain the straight line of best fit in the plot above, the code `X @ beta` is used. \n",
    "This is the matrix implementation of $y = m x + c$.\n",
    "```\n",
    "````\n",
    "\n",
    "## The `scikit-learn` way\n",
    "\n",
    "Another method that can be used to perform the same operation is available in the `scikit-learn` package, a Python package focusing on machine learning tools. \n",
    "The approach of using `scikit-learn` is slightly different, because `scikit-learn` methods typically follow a machine learning \"training\" approach. \n",
    "First, a `LinearRegression()` object is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to get our data in a form that can be ingested by the `LinearRegression` object, it is necessary to withdraw the NumPy arrays from the `pandas.DataFrame` and then \"reshape\" the arrays. \n",
    "This reshaping ensures that the arrays are two-dimensional, the expected dimensionality for `scikit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['speed (kph)'].to_numpy().reshape(-1, 1)\n",
    "y = data['heart rate (bpm)'].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{margin}\n",
    "```{note}\n",
    "Fitting is not a good term for this, as there is no numerical optimisation occurring in linear regression. \n",
    "As will be seen later, fitting is only necessary for non-linear analysis.\n",
    "```\n",
    "````\n",
    "The \"fitting\" is then done, by passing the reshaped independent and dependent variances to the `fit` method for the `LinearRegression` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different regression parameters can then be obtained as attributes of the `model`. \n",
    "For example, the slope is `coef_` (short for coefficients) and the intercept is `intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides a convenience function for producing the line of best fit over a given set of *x*-values, `predict`. \n",
    "This means that the plot can be produced as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "data.plot(x='speed (kph)', y='heart rate (bpm)', marker='.', linestyle='', ax=ax)\n",
    "ax.plot(data['speed (kph)'], model.predict(x), 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the slope and intercept are the same for both methods. \n",
    "This is because linear regression has a definite result, i.e., there is no random fitting procedure involved and therefore for the same input data, the same result will always be found."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "special-topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
