{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov chain Monte Carlo Sampling\n",
    "\n",
    "Markov chain Monte Carlo (MCMC) sampling is a powerful and popular approach to likelihood, and [posterior](./posteriors.html) sampling. \n",
    "Within the name, there are two concepts that we should try and understand before we look at the implementation of a MCMC algorithm; Markov chains and Monte Carlo. \n",
    "\n",
    "## Monte Carlo\n",
    "\n",
    "Monte Carlo sampling is an approach used to estimate some numerical result. \n",
    "It is based on the use of random sampling, hoping that we will get an estimate of the true result with enough random samples. \n",
    "A popular example of this you may have seen is using Monte Carlo to estimate &pi;. \n",
    "\n",
    "```{figure} ../images/pi-sample.png\n",
    "---\n",
    "name: pi-sample\n",
    "height: 300px\n",
    "---\n",
    "A diagram showing how the sampling is performed in the Monte Carlo estimation of &pi;, where the stones in the quarter-circle are blue and those outside are yellow.\n",
    "```\n",
    "\n",
    "We can think of this as randomly throwing stones on a square area of 1-by-1 metre. \n",
    "Suppose the stone lands a distance of less than 1 metre from the origin (i.e., the [norm](./../maths/vectors.md) of the vector from the stone to the origin is less than 1). \n",
    "In that case, we say it has landed inside the quarter-circle and therefore counts to the integral or area (or the points outside this quarter-cirle are *rejected*). \n",
    "The area of a quarter-circle is given by, \n",
    "\n",
    "$$\n",
    "A_{\\textrm{circ}} = \\frac{\\pi r^2}{4}, \n",
    "$$\n",
    "\n",
    "where, $r$ is 1 metre.\n",
    "The area of the 1-by-1 metre square is, \n",
    "\n",
    "$$\n",
    "A_{\\textrm{squ}} = r^2, \n",
    "$$\n",
    "\n",
    "and this is approximated by the total number of stones thrown. \n",
    "From computing the ratio of the stones inside the quarter-circle to the total stones thrown, we estimate the following, \n",
    "\n",
    "$$\n",
    "\\frac{A_{\\textrm{circ}}}{A_{\\textrm{squ}}} = \\frac{\\pi r^2}{4} \\frac{1}{r^2} = \\frac{\\pi}{4} \\implies \\pi = 4 \\frac{A_{\\textrm{circ}}}{A_{\\textrm{squ}}} \n",
    "$$\n",
    "\n",
    "This can be implemented easily in NumPy code, as shown below, where one million samples were taken/stones were thrown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "\n",
    "positions = uniform.rvs(loc=0, scale=1, size=(1_000_000, 2))\n",
    "distances = np.linalg.norm(positions, axis=1)\n",
    "in_circle = distances[distances < 1]\n",
    "4 * in_circle.size / distances.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In likelihood sampling, instead of using random samples to estimate an integral, we want to estimate the structure of a probability distribution. \n",
    "However, to make our sampling more efficient, we harness Markov chains. \n",
    "\n",
    "## Markov chains\n",
    "\n",
    "A Markov chain is a mathematical system, similar in many ways to a random walk. \n",
    "The Markov chain undergoes transitions from one state to another, sampling some (potentially infinite) set of states. \n",
    "Throughout this sampling, the Markov property is followed.\n",
    "> Markov property: the future state depends only on the present state, not the past states' sequence.\n",
    "\n",
    "This memorylessness makes Markov chain valuable for application in many areas of science. \n",
    "However, here we will look at how they are used with Monte Carlo rejection to sample a likelihood probability distribution function.\n",
    "\n",
    "## Building an MCMC Algorithm\n",
    "\n",
    "We will use the first order rate equation data from earlier to look at how this algorithm works. \n",
    "Let's read this data and set up the model function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from scipy.stats import norm\n",
    "\n",
    "data = pd.read_csv('../data/first-order.csv')\n",
    "\n",
    "D = [norm(data['At'][i], data['At_err'][i]) for i in range(len(data))]\n",
    "\n",
    "def first_order(t, k, A0):\n",
    "    \"\"\"\n",
    "    A first order rate equation.\n",
    "    \n",
    "    :param t: The time to evaluate the rate equation at.\n",
    "    :param k: The rate constant.\n",
    "    :param A0: The initial concentration of A.\n",
    "    \n",
    "    :return: The concentration of A at time t.\n",
    "    \"\"\"\n",
    "    return A0 * np.exp(-k * t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also necessary to create the likelihood function. \n",
    "````{margin}\n",
    "```{note}\n",
    "Be aware, that here the likelihood and negative likelihood functions are separate, the reason for this will become clear. \n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(theta):\n",
    "    \"\"\"\n",
    "    The likelihood function for the first order rate equation.\n",
    "    \n",
    "    :param theta: The parameters to evaluate the negative likelihood at.\n",
    "    \n",
    "    :return: The likelihood at theta.\n",
    "    \"\"\"\n",
    "    return np.sum([d.pdf(first_order(t, theta[0], theta[1])) \n",
    "                   for d, t in zip(D, data['t'])])\n",
    "\n",
    "def negative_likelihood(theta):\n",
    "    \"\"\"\n",
    "    The negative likelihood function for the first order rate equation.\n",
    "    \n",
    "    :param theta: The parameters to evaluate the negative likelihood at.\n",
    "    \n",
    "    :return: The negative likelihood at theta.\n",
    "    \"\"\"\n",
    "    return -likelihood(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform MCMC sampling, we need a place for our algorithm to start from. \n",
    "Using a position close to the maximum likelihood values is common practice. \n",
    "Therefore, below we optimise the negative likelihood to get the parameter values we saw previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "res = minimize(negative_likelihood, [0.1, 1])\n",
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these values, we will create ten *walkers*. \n",
    "These are ten unique Markov chains that we will use in the sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_chains = norm.rvs(size=(10, 2), random_state=1) * 5e-4 + res.x\n",
    "init_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we begin the sampling. \n",
    "The MCMC sampling process is shown pictorially in {numref}`mcmc`. \n",
    "\n",
    "```{figure} ../images/mcmc.png\n",
    "---\n",
    "name: mcmc\n",
    "width: 80%\n",
    "---\n",
    "A pictorial description of how MCMC leads to an estimate of the probability distribution. \n",
    "```\n",
    "\n",
    "The basic idea is to make some pertubation from the previous position and then see how much that has changed the likelihood. \n",
    "If the likelihood has improved, the move is accepted. \n",
    "If the likelihood has decreases, then the move will be accepted if the ratio of the likelihood change is greater than a uniformly sampled random number from 0 to 1. \n",
    "This means that sometimes, we accept moves to lower likelihood, increasing our ability to sample the distribution. \n",
    "If the move is rejected, we store the current value of the parameters. \n",
    "Let's see that in code. \n",
    "````{margin}\n",
    "```{note}\n",
    "This algorithm is known as the Metropolis Hastings sampling algorithm {cite}`Metropolis1953,Hastings1970`. \n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "step_std = 5e-3\n",
    "\n",
    "chains = np.zeros((n_samples, *init_chains.shape))\n",
    "chains[0] = init_chains\n",
    "current_likelihood = np.array([likelihood(parameters) for parameters in init_chains])   \n",
    "\n",
    "for i in range(1, n_samples):\n",
    "    new_theta = norm(chains[i-1], \n",
    "                     np.ones((10, 2)) * step_std).rvs(random_state=i)\n",
    "    new_likelihood = np.array([likelihood(parameters) \n",
    "                               for parameters in new_theta])\n",
    "\n",
    "    acceptance_ratio = new_likelihood / current_likelihood\n",
    "\n",
    "    accepted = uniform(loc=0, \n",
    "                       scale=1).rvs(size=10, \n",
    "                                    random_state=i) < acceptance_ratio\n",
    "    chains[i] = np.where(accepted[:, np.newaxis], new_theta, chains[i-1])\n",
    "\n",
    "    current_likelihood = np.array([likelihood(parameters) \n",
    "                                   for parameters in chains[i]])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `step_std` value is a hyperparameter for our sampling process that typically requires tuning. \n",
    "After performing all of the sampling, there are two tasks to take care of.\n",
    "The first is reducing autocorrelation and the second is to reshape the samples. \n",
    "\n",
    "```{admonition} Autocorrelation in Markov Chains\n",
    ":class: tip\n",
    "The fact that a Markov chain depends on the previous position can lead to correlation between samples. \n",
    "Consider a particle on a ranomd walk, the position it has reached after some number of steps necessarily affects where it will reach in the next step. \n",
    "It is possible to [estimate the autocorrelation time](https://emcee.readthedocs.io/en/stable/tutorials/autocorr/#computing-autocorrelation-times) of a Markov chain. \n",
    "Once you know the autocorrelation time, you would typically use every *n*th sample, where *n* is that time. \n",
    "This is known as *thinning*, below, we *thin* by taking every 10th sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_chain = chains[::10].reshape(-1, 2)\n",
    "flat_chain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 10 000 independent samples of the two parameters. \n",
    "We can histogram these to get an estimate of the probability density function. \n",
    "````{margin}\n",
    "```{note}\n",
    "For this figure, we have used `seaborn`. \n",
    "However, other libraries, such as `corner` exist for this plotting. \n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "chains_df = pd.DataFrame(flat_chain, columns=['k', 'A0'])\n",
    "sns.jointplot(data=chains_df, x='k', y='A0', kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to then calculate the first order model for all of the values in the flatten chain and plot a range of models that represent the one standard deviation credible interval for the data given the model (the green shaded area). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_std = first_order(data['t'].values[:, np.newaxis], \n",
    "                      flat_chain[:, 0], \n",
    "                      flat_chain[:, 1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(data['t'], data['At'], data['At_err'], fmt='o', zorder=10)\n",
    "ax.plot(data['t'], np.mean(one_std, axis=1), 'g', zorder=5)\n",
    "ax.fill_between(data['t'],\n",
    "                    *np.percentile(one_std, [16, 84], axis=1),\n",
    "                    alpha=0.3,\n",
    "                    color='g',\n",
    "                    lw=0)\n",
    "ax.set_xlabel('Time / s')\n",
    "ax.set_ylabel('[A] / M')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute summary statistics from the flatten chain. \n",
    "However, these should be treated with caution, able we have the whole distribution, not only some single value that describes it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_chain.mean(axis=0), flat_chain.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice the the mean of the flat chain is similar to the maximum likelihood values, but not the same, as the distributions, in particular for $[A]_0$ aren't completely normally distributed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "special-topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
