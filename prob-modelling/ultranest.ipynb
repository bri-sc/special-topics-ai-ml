{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultranest for Nested Sampling\n",
    "\n",
    "We will look at the following data to investigate nested sampling using the `ultranest` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/signals.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is the measurement of some signal $y$, as a function of $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(data['x'], data['y'], yerr=data['yerr'])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question we want to answer about this data is if one or two Gaussian signals are present. \n",
    "We can think of this as two models: one for a single signal and a more complex one for two signals. \n",
    "This is the perfect opportunity to use Bayesian model selection. \n",
    "\n",
    "Before constructing either model, we will create the likelihood function, which will be the same either way but with a different input model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "data_distribution = [norm(loc=loc, scale=scale) for loc, scale in zip(data['y'], data['yerr'])]\n",
    "\n",
    "def likelihood(params, model):\n",
    "    \"\"\"\n",
    "    A general likelihood function for a model with Gaussian errors.\n",
    "    \n",
    "    :param params: The parameters of the model.\n",
    "    :param model: The model function.\n",
    "    \n",
    "    :return: The likelihood of the model given the data.\n",
    "    \"\"\"\n",
    "    model_y = model(data['x'], params)\n",
    "    return np.sum([d.logpdf(m) for d, m in zip(data_distribution, model_y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to build a simpler model and compute the evidence. \n",
    "We start by creating priors for the mean and standard deviation of the single Gaussian function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, norm\n",
    "\n",
    "priors_one = [norm(220, 20), \n",
    "              uniform(10, 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean has a normally distributed prior ($\\mathcal{N}(220, 20)$) and the standard deviation is uniform ($\\mathcal{U}(10, 20)$).\n",
    "\n",
    "The next step is to create a prior transform function. \n",
    "This function converts uniformly distributed random variables to random variables drawn from the priors of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_transform_one(u):\n",
    "    \"\"\"\n",
    "    Transform the uniform random variables `u` to the model parameters.\n",
    "    \n",
    "    :param u: Uniform random variables\n",
    "    \n",
    "    :return: Model parameters\n",
    "    \"\"\"\n",
    "    return [p.ppf(u_) for p, u_ in zip(priors_one, u)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct the model and create a model-specific likelihood and function to be fed to the sampler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_one(x, params):\n",
    "    \"\"\"\n",
    "    A simpler single Gaussian model.\n",
    "    \n",
    "    :param x: The x values\n",
    "    :param params: The model parameters\n",
    "    \n",
    "    :return: The y values\n",
    "    \"\"\"\n",
    "    return norm(loc=params[0], scale=params[1]).pdf(x)\n",
    "\n",
    "def likelihood_one(params):\n",
    "    \"\"\"\n",
    "    The likelihood function for the simpler model.\n",
    "    \n",
    "    :param params: The model parameters\n",
    "    \n",
    "    :return: The likelihood\n",
    "    \"\"\"\n",
    "    return likelihood(params, model_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is then passed to the `ultranest.ReactiveNestedSampler`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest\n",
    "\n",
    "sampler_one = ultranest.ReactiveNestedSampler(['mu1', 'sigma1'], likelihood_one, prior_transform_one)\n",
    "sampler_one.run(show_status=False)\n",
    "sampler_one.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_one.results['logz'], sampler_one.results['logzerr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do the same process for a more complex two-Gaussian model. \n",
    "Note that we have four priors now instead of two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors_two = [norm(220, 20), \n",
    "              uniform(10, 20), \n",
    "              norm(500, 100),\n",
    "              uniform(100, 200)]\n",
    "\n",
    "def prior_transform_two(u):\n",
    "    \"\"\"\n",
    "    Transform the uniform random variables `u` to the model parameters for the more complex model.\n",
    "    \n",
    "    :param u: Uniform random variables\n",
    "    \n",
    "    :return: Model parameters\n",
    "    \"\"\"\n",
    "    return [p.ppf(u_) for p, u_ in zip(priors_two, u)]\n",
    "\n",
    "def model_two(x, params):\n",
    "    \"\"\"\n",
    "    A more complex double Gaussian model.\n",
    "    \n",
    "    :param x: The x values\n",
    "    :param params: The model parameters\n",
    "    \n",
    "    :return: The y values\n",
    "    \"\"\"\n",
    "    return (norm(loc=params[0], scale=params[1]).pdf(x) + norm(loc=params[2], scale=params[3]).pdf(x)) * 0.5\n",
    "\n",
    "def likelihood_two(params):\n",
    "    \"\"\"\n",
    "    The likelihood function for the more complex model.\n",
    "    \n",
    "    :param params: The model parameters\n",
    "    \n",
    "    :return: The likelihood\n",
    "    \"\"\"\n",
    "    return likelihood(params, model_two)\n",
    "\n",
    "sampler_two = ultranest.ReactiveNestedSampler(['mu1', 'sigma1', 'mu2', 'sigma2'], likelihood_two, prior_transform_two)\n",
    "sampler_two.run(show_status=False)\n",
    "sampler_two.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_two.results['logz'], sampler_two.results['logzerr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the Bayes factor for these two models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_B = sampler_two.results['logz'] - sampler_one.results['logz']\n",
    "log_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is decisive evidence for the more complex model. \n",
    "Therefore, we would be able to continue our analysis by considering the signal shown by the two Gaussians. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "special-topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
