{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priors\n",
    "\n",
    "In the previous page, we introduced Bayes' theorem, which inverts conditional probabilities. \n",
    "The form of Bayes' theorem we met was, \n",
    "\n",
    "$$\n",
    "p(A | B) = \\frac{p(B | A) p(A)}{p(B)}.\n",
    "$$\n",
    "\n",
    "````{margin}\n",
    "```{note}\n",
    "It is slightly unfair to call these prior *uninformative*, given they inform on the minimum and maximum values that can be taken. \n",
    "However, this name is popular in the field. \n",
    "```\n",
    "````\n",
    "In this form, $p(A)$ is the prior probability or simply the *prior*. \n",
    "It ensures that what we already know about the world is included in our analysis. \n",
    "We achieve this, for example, by saying that our parameter $A$ cannot be less than 0 and cannot be greater than 1.\n",
    "This way, we would use a uniform prior probability distribution. \n",
    "We imposed this *uninformative prior* when implementing PyMC using the `pm.Uniform` objects for our parameters. \n",
    "\n",
    "## Informative Priors\n",
    "\n",
    "One of the important benefits of the Bayesian approach is to take advantage of what we already know about the world. \n",
    "We will come back to highlight this impact in the next section. \n",
    "Consider how we can create a meaningful prior probability based on some prior measurement. \n",
    "\n",
    "Consider if we are trying to determine the rate constant, $k$, and the concentration of $A$ at time $0$ in the previous example. \n",
    "When we prepare the experiment, we have some understanding of the initial concentration, for example, from the preparation of our system. \n",
    "Therefore, we can say that the initial concentration is 7.5 &plusmn; 0.5 M.\n",
    "This can be described with a normal probability distribution, which we visualise below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm\n",
    "\n",
    "mu = 7.5 \n",
    "sigma = 0.5 \n",
    "\n",
    "A_0 = norm(mu, sigma)\n",
    "x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, A_0.pdf(x))\n",
    "ax.set_xlabel('$[A]_0$ / M')\n",
    "ax.set_ylabel('$p([A]_0)$ / M$^{-1}$')\n",
    "ax.set_ylim(0, None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also consider where there are some complementary measurements; for example, some previous work may have measured the rate constant, $k$, that we are interested in. \n",
    "Consider if the previous work measured $k$ as 0.15 &plusmn; 0.01 s<sup>-1</sup>, which we can present as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.15\n",
    "sigma = 0.01 \n",
    "\n",
    "k = norm(mu, sigma)\n",
    "x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, k.pdf(x))\n",
    "ax.set_xlabel('$[A]_0$ / M')\n",
    "ax.set_ylabel('$p([A]_0)$ / M$^{-1}$')\n",
    "ax.set_ylim(0, None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that this prior probability is very low at the maximum likelihood estimation of $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.pdf(0.1046)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, this prior knowledge may be influential in the estimation of the probability of the model, given the data. \n",
    "This is an important input in our analysis so that we can look at this calculation now. \n",
    "\n",
    "```{admonition} The Subjectivity of Priors\n",
    ":class: tip\n",
    "Opponents of Bayesian modelling claim that using a prior is a bias to get the answer you want. \n",
    "This is a fair argument, so to counter it, Bayesian practitioners must be explicit about why they picked particular priors and justify their decisions. \n",
    "For example, if you chose some normally distributed prior around some value, it is important that you state *why* this was selected. \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "special-topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
